% Created 2022-08-06 sam. 16:15
% Intended LaTeX compiler: pdflatex
\documentclass[10pt]{beamer}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usepackage{minted}
\usepackage[T1]{fontenc}
\usepackage{pmboxdraw}
\usetheme{Berkeley}
\definecolor{UBCblue}{rgb}{0.54706, 0.13725, 0.26667} % UBC Blue (primary)
\usecolortheme[named=UBCblue]{structure}
\setlength{\parskip}{5pt}
\newcommand{\footnoteframe}[1]{\footnote[frame]{#1}}
\addtobeamertemplate{footnote}{}{\vspace{2ex}}
\usepackage{xcolor}
\definecolor{LightGray}{gray}{0.95}
\usetheme{default}
\author{Jay Morgan}
\date{<TODO>}
\title{Machine Learning}
\subtitle{Lecture 1 - Introductions}
\hypersetup{
 pdfauthor={Jay Morgan},
 pdftitle={Machine Learning},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 28.1 (Org mode 9.5.4)}, 
 pdflang={English}}
\begin{document}

\maketitle

\section*{Introduction}
\label{sec:orgdcf2d37}

\subsection*{Course Organisation}
\label{sec:org9d70cf6}

\begin{frame}[label={sec:orgfcf756a}]{Welcome!}
Welcome to all the new students! Here I am going to be talking about Machine Learning
and all of the great things that this "technology" has to offer. To begin our course,
I shall start with a bit of house keeping -- more specifically, I will be talking
about what exactly we'll be learning about in the course (Machine Learning is a broad
subject after-all). In addition, I will tell you where you can find the resources
related to the course and how you can contact me, should you have any questions.
\end{frame}

\begin{frame}[label={sec:orgdc545e6}]{What this course is about?}
In this course, we will be learning about Machine Learning: firstly, what Machine
Learning actually is; secondly, we'll take a look at some of the algorithms within
the scope of Machine Learning, and develop an intuition about how these algorithms
work and when they would be useful; and finally, how we can compare and evaluate the
algorithms we've learnt about.
\end{frame}

\begin{frame}[label={sec:org81b02c1}]{How this course will be taught}
I intended to deliver this course via a series of lectures. These lectures will be
accompanied by the PDF lecture slides, in which I will provide the definitions and
provide reference links should you wish to do some extra reading.
\end{frame}

\begin{frame}[label={sec:org905d8ac}]{Outline of the course}
\begin{center}
\begin{tabular}{rlll}
Lecture & Expected date & Length & Topic\\
\hline
1 & NOW & 2 hours & Introduction\\
 &  &  & \\
\end{tabular}
\end{center}
\end{frame}

\subsection*{Reading the lectures}
\label{sec:orgb09c647}

\begin{frame}[label={sec:orgb55805e},fragile]{Source code}
 In some situations, I would also like to supplement my algorithmic definitions with
some programming code -- for this I will use the \href{https://julialang.org/}{Julia} programming language. The code
snippets would look something like:

\begin{minted}[frame=lines,linenos=true,firstnumber=last,fontsize=\footnotesize,bgcolor=LightGray,xleftmargin=5pt,tabsize=2,breaklines=true,numbersep=10pt]{julia}
x = Float32.([1, 2, 3, 4]);
y = x .+ randn(length(x))
\end{minted}

\begin{verbatim}
4-element Vector{Float64}:
 1.8817576050704024
 2.051062476034138
 4.340649570113399
 3.1284623590241476
\end{verbatim}
\end{frame}

\begin{frame}[label={sec:org74f7ba7}]{References}
In some cases, and is the norm with academic traditions, we'll want to include a
reference, a link to previous written works.

Here is an example of a sentence that includes a reference:

"This is a very important sentence which I assert to be true, to convince you of this
fact I shall appeal to authority and include a reference:
(Shalev-Shwartz, Shai and Ben-David, Shai, 2014)"

More information on the referenced material (such as title, publishing date) will be
found in the bibliography slide (or bottom of the webpage if you're viewing the HTML
version of the lectures).
\end{frame}

\begin{frame}[label={sec:org0021423}]{About Me}
My name is Dr Jay Morgan. I am a researcher at the Université de Toulon, where I am
developing Deep Learning models (a sub-field of Machine Learning research) for the
study of astrophysical phenomenon.

You can find more information and links on my personal (LIS-Lab) website:
\url{https://pageperso.lis-lab.fr/jay.morgan/}

I also publish libraries and source code online:
\begin{itemize}
\item Github: \url{https://github.com/jaypmorgan}
\item Gitlab: \url{https://gitlab.com/jaymorgan}
\item Source Hut: \url{https://sr.ht/\~jaymorgan/}
\end{itemize}

If you have any questions, you can email me at jay.morgan@univ-tln.fr
\end{frame}

\begin{frame}[label={sec:org492f044}]{Where you can find the resources}
I try to make this course as accessible as possible, which means that I host these
slides in a variety of ways to suit you.

Firstly, you can find the links to all my courses on my personal website at:
\url{https://pageperso.lis-lab.fr/jay.morgan/teaching.html}

Here you can find the links to each lecture in a PDF or HTML format. Additionally,
you can view the source code used to make these lectures on source hut:
\url{https://git.sr.ht/\~jaymorgan/teaching}. On this git repository you can find all my
lectures from all years.
\end{frame}

\section*{What is learning, anyway?}
\label{sec:orgb1550be}

\subsection*{Learning about Learning}
\label{sec:org2c4e97d}

\begin{frame}[label={sec:org3b27963}]{Let's answer the question of learning}
We'll begin our journey into the world of Machine Learning by tackling the question
of what it means to 'learn' -- how may a machine actually \emph{learn} anything?
\end{frame}

\begin{frame}[label={sec:org7e0e479}]{Study of Mice}
To begin to answer the question of learning, we may turn to nature for
advice. Principally, if we look at the studies conducted with Mice we find some idea
to notion of learning (Shalev-Shwartz, Shai and Ben-David, Shai, 2014).
\end{frame}

\begin{frame}[label={sec:orgdc8692e}]{Bait-shyness}
\end{frame}

\begin{frame}[label={sec:org81625d8}]{Pigeon superstition}
\end{frame}

\begin{frame}[label={sec:org5b3cd2b}]{Computer Programs}
For a more formal definition of how computer programs could be said to learn, we have:

\begin{quote}
A computer program is said to learn from experience \(E\) with respect
to some class of tasks \(T\) and performance measure \(P\), if its performance
a tasks in \(T\), as measured by \(P\), improves with experience \(E\).
\end{quote}

(Mitchell, Tom M, 1997)
\end{frame}

\begin{frame}[label={sec:org2a18575}]{When might we need Machine Learning}
\begin{itemize}
\item When problems are difficult to describe.
\end{itemize}
\end{frame}

\begin{frame}[label={sec:orgb8912cb}]{Different types of Learning}
\begin{itemize}
\item Supervised Learning
\item Unsupervised / self-supervised Learning
\item Reinforcement Learning
\end{itemize}
\end{frame}

\begin{frame}[label={sec:org432f690}]{Supervised Learning}
\begin{itemize}
\item Input and outputs are provided to the algorithm.
\item Tuple
\end{itemize}
\end{frame}

\begin{frame}[label={sec:org8c21865}]{Unsupervised Learning}
\begin{itemize}
\item Output is not provided to the model.
\item Also called self-supervised -- why, text modelling.
\item Clustering
\end{itemize}
\end{frame}

\begin{frame}[label={sec:org9f23bdc}]{Reinforcement Learning}
\begin{itemize}
\item Agent interacts with an environment.
\item Gains a reward based on interactions.
\item Over many 'games', the interactions will become better.
\end{itemize}
\end{frame}

\subsection*{Terminology}
\label{sec:orgf2a2b86}

\begin{frame}[label={sec:orgc77f316}]{What will our data look like?}
Data in Machine Learning applications can come in a variety of different formats. The
most typical data formats we might see are:

\begin{itemize}
\item Tables
\item Images/Videos
\item Text
\item Sound
\end{itemize}

These are the initial formats, though, before actually doing any learning, we will
want to transform them into a different representation that we can use.
\end{frame}

\begin{frame}[label={sec:org2888843}]{Tables}
A table, or tabular, format is a \(n \times m\) set of data with \(n\) samples or
examples, and \(m\) features for each sample. For example:
\begin{center}
\begin{tabular}{rll}
ID & \ldots{} & \\
\hline
1 &  & \\
2 &  & \\
\end{tabular}
\end{center}
\end{frame}

\begin{frame}[label={sec:org19253ff}]{Images/Videos}
\begin{itemize}
\item Matrix (2D/3D)
\item Video composition of Images in a sequence
\end{itemize}
\end{frame}

\begin{frame}[label={sec:org976114e}]{Text}
\begin{itemize}
\item Composition of words
\item Can be in order, but doesn't have to be!
\item What is considered a word?
\end{itemize}
\end{frame}

\begin{frame}[label={sec:org4521d7f}]{Time-series}
\begin{itemize}
\item Sequence of values (vector with a time component)
\item Example is a sound wave.
\end{itemize}
\end{frame}

\begin{frame}[label={sec:org1f0c166}]{Inputs/Outputs}
Within our data, each value will take on a certain type.

\begin{center}
\begin{tabular}{ll}
Name & Example\\
\hline
Discrete & Total number of students\\
Continuious & Height of a student\\
\hline
Ordinal & element of \{Low, Med, High\}\\
Nominal & element of \{'dog', 'cat'\}\\
\end{tabular}
\end{center}

\begin{itemize}
\item Discrete:
\item Continuious:
\item Ordinal:
\item Nominal:
\end{itemize}
\end{frame}

\begin{frame}[label={sec:org36c274e}]{Types of Outputs -- Regression \& Classification}
\begin{itemize}
\item Regression - to continuious
\item Classification to discrete
\end{itemize}
\end{frame}

\subsection*{Example Problems}
\label{sec:org90a8201}

\begin{frame}[label={sec:org08272bf},fragile]{Boston House Prices Dataset -- Tabular Regression}
 \begin{minted}[frame=lines,linenos=true,firstnumber=last,fontsize=\footnotesize,bgcolor=LightGray,xleftmargin=5pt,tabsize=2,breaklines=true,numbersep=10pt]{julia}
using DataFrames
using MLDatasets: BostonHousing
dataset = BostonHousing();
dataset[1:5]
\end{minted}

\begin{verbatim}
(features = 5×13 DataFrame
 Row │ CRIM     ZN       INDUS    CHAS   NOX      RM       AGE      DIS      RAD    TAX    PTRATIO  B        LSTAT   
     │ Float64  Float64  Float64  Int64  Float64  Float64  Float64  Float64  Int64  Int64  Float64  Float64  Float64 
─────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────
   1 │ 0.00632     18.0     2.31      0    0.538    6.575     65.2   4.09        1    296     15.3   396.9      4.98 
   2 │ 0.02731      0.0     7.07      0    0.469    6.421     78.9   4.9671      2    242     17.8   396.9      9.14
   3 │ 0.02729      0.0     7.07      0    0.469    7.185     61.1   4.9671      2    242     17.8   392.83     4.03
   4 │ 0.03237      0.0     2.18      0    0.458    6.998     45.8   6.0622      3    222     18.7   394.63     2.94
   5 │ 0.06905      0.0     2.18      0    0.458    7.147     54.2   6.0622      3    222     18.7   396.9      5.33 , targets = 5×1 DataFrame
 Row │ MEDV
     │ Float64
─────┼─────────
   1 │    24.0
   2 │    21.6
   3 │    34.7
   4 │    33.4
   5 │    36.2)
\end{verbatim}
\end{frame}

\begin{frame}[label={sec:orgfc4eea1},fragile]{Iris Dataset -- Tabular Classification}
 \begin{minted}[frame=lines,linenos=true,firstnumber=last,fontsize=\footnotesize,bgcolor=LightGray,xleftmargin=5pt,tabsize=2,breaklines=true,numbersep=10pt]{julia}
using MLDatasets: Iris
dataset = Iris();
dataset[1:5]
\end{minted}

\begin{verbatim}
(features = 5×4 DataFrame
 Row │ sepallength  sepalwidth  petallength  petalwidth
     │ Float64      Float64     Float64      Float64
─────┼──────────────────────────────────────────────────
   1 │         5.1         3.5          1.4         0.2
   2 │         4.9         3.0          1.4         0.2
   3 │         4.7         3.2          1.3         0.2
   4 │         4.6         3.1          1.5         0.2
   5 │         5.0         3.6          1.4         0.2, targets = 5×1 DataFrame
 Row │ class
     │ String15
─────┼─────────────
   1 │ Iris-setosa
   2 │ Iris-setosa
   3 │ Iris-setosa
   4 │ Iris-setosa
   5 │ Iris-setosa)
\end{verbatim}
\end{frame}

\begin{frame}[label={sec:orgf8a866d},fragile]{MNIST Dataset -- Image Classification}
 \begin{minted}[frame=lines,linenos=true,firstnumber=last,fontsize=\footnotesize,bgcolor=LightGray,xleftmargin=5pt,tabsize=2,breaklines=true,numbersep=10pt]{julia}
using MLDatasets: MNIST
dataset = MNIST();
dataset[1:5]
\end{minted}

\begin{verbatim}
(features = [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], targets = [5, 0, 4, 1, 9])
\end{verbatim}
\end{frame}

\begin{frame}[label={sec:org682382e},fragile]{MNIST Dataset -- Image Classification}
 \begin{minted}[frame=lines,linenos=true,firstnumber=last,fontsize=\footnotesize,bgcolor=LightGray,xleftmargin=5pt,tabsize=2,breaklines=true,numbersep=10pt]{julia}
using Plots
p = heatmap(dataset[1].features', yflip=true, colorbar=false)
p = title!("Label/Target: $(dataset[1].targets)")
savefig(p, "images/mnist-example.png")
\end{minted}

\begin{verbatim}



ERROR: SystemError: opening file "/home/jaymorgan/Nextcloud/Teaching/images/mnist-example.png": Aucun fichier ou dossier de ce type
Stacktrace:
  [1] systemerror(p::String, errno::Int32; extrainfo::Nothing)
    @ Base ./error.jl:174
  [2] #systemerror#68
    @ ./error.jl:173 [inlined]
  [3] systemerror
    @ ./error.jl:173 [inlined]
  [4] open(fname::String; lock::Bool, read::Nothing, write::Nothing, create::Nothing, truncate::Bool, append::Nothing)
    @ Base ./iostream.jl:293
  [5] open(fname::String, mode::String; lock::Bool)
    @ Base ./iostream.jl:355
  [6] open(fname::String, mode::String)
    @ Base ./iostream.jl:355
  [7] open(::Plots.var"#277#278"{Plots.Plot{Plots.GRBackend}}, ::String, ::Vararg{String}; kwargs::Base.Pairs{Symbol, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
    @ Base ./io.jl:328
  [8] open
    @ ./io.jl:328 [inlined]
  [9] png(plt::Plots.Plot{Plots.GRBackend}, fn::String)
    @ Plots ~/.julia/packages/Plots/SkUg1/src/output.jl:4
 [10] savefig(plt::Plots.Plot{Plots.GRBackend}, fn::String)
    @ Plots ~/.julia/packages/Plots/SkUg1/src/output.jl:115
 [11] top-level scope
    @ none:1
\end{verbatim}
\end{frame}

\begin{frame}[label={sec:org7938f01}]{IMDB Reviews -- Text Classification/Regression}
\end{frame}

\begin{frame}[label={sec:orgaca0941}]{Ham or Spam -- Text Classification}
\end{frame}

\subsection*{Concerns \& Considerations}
\label{sec:org9adece7}

\begin{frame}[label={sec:org459a2fa}]{Compute resources -- environmental concerns}
\end{frame}

\begin{frame}[label={sec:orgc2dcdb4}]{Bias}
\end{frame}

\begin{frame}[label={sec:org228022f}]{Personal information}
\begin{itemize}
\item i.e. GANs reproducing exactly.
\end{itemize}
\end{frame}

\begin{frame}[label={sec:orgc8c2f52}]{Mental health of optimisation algorithms}
\end{frame}

\section*{Summary}
\label{sec:orge3b6472}

\subsection*{What is Machine Learning}
\label{sec:org5808e83}

\begin{frame}[label={sec:orga3eefa4}]{Problem statement}
\end{frame}

\section*{Bibliography}
\label{sec:org61e2e72}

\begin{frame}[label={sec:org09895c0}]{Bibliography}
\noindent
Mitchell, Tom M (1997). \emph{Machine learning}, McGraw-hill New York.

\noindent
Shalev-Shwartz, Shai and Ben-David, Shai (2014). \emph{Understanding machine learning: From theory to algorithms}, Cambridge university press.
\end{frame}
\end{document}
