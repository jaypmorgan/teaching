% Created 2022-08-01 lun. 18:01
% Intended LaTeX compiler: pdflatex
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usepackage{minted}
\author{Jay Morgan}
\date{04-06-2022}
\title{Machine Learning (2022-2023) -- Course Outline}
\hypersetup{
 pdfauthor={Jay Morgan},
 pdftitle={Machine Learning (2022-2023) -- Course Outline},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 28.1 (Org mode 9.5.3)}, 
 pdflang={English}}
\begin{document}

\maketitle
\tableofcontents

Total delivered time: 10 hours
Delivered via: Lectures
Book accompaniment: Data Mining -- Practical Machine Learning Tools and Techniques
(Fourth Edition), Witten et al.
Programming language used: Julia -- implementation closely follows the mathematical formulae

The course is intended to give students an introduction to Machine Learning,
providing them with firm background in this study should this wish to continue this
research in future and improve the techniques and ideas of the discipline. From this
course, they will be introduced into the concepts of Machine Learning, i.e. what is
learning, and considerations such as bias/variance and
over-fitting/under-fitting. This course will also introduce them into some of the
more fundamental algorithms or techniques, such as decision trees and k-means.

\section{Lecture 1 - What is Machine Learning?}
\label{sec:org6ca7e23}

\begin{itemize}
\item Introduction to course:
\begin{itemize}
\item Who I am.
\item What this course will be about.
\item Where you can find reference material.
\end{itemize}

\item What does it mean to learn, and how can a machine learn anything?
\item Some terminology -- a model, a dataset (comprised of inputs, and outputs), and
predictions and ground-truth.
\item A practical example using the classic iris dataset -- we won't solve this just yet,
it is just a motivating classification problem.
\item Another practical example of predicting boston house prices -- this will come in
handy for the next section.
\item What can machine learning be used for?
\item Ethical considerations.
\end{itemize}

\section{A Machine Learning 'Hello, World!' -- A Linear Regressor}
\label{sec:org5486558}

\begin{itemize}
\item Re-introduce the boston housing prices dataset -- what are the input variables and
output response?
\item A little analysis on the dataset -- usefulness of the variables for the prediction.
\item Choosing one of the input variables to estimate the price.
\item What is a linear regression model? -- straight line equation for prediction.
\item How well does a random linear model do?
\item How do we make the linear model more accurate -- change the slope and intercept.
\item How do we pragmatically select the best weights?
\item Measuring the loss.
\item Visualising the loss w.r.t. slope.
\item Gradient descent algorithm. (what do we mean by convex and non-convex)?
\item Getting the best linear regression model.
\item Closed form solution -- even with the closed-form solution, why might we want to
use gradient descent? When the dataset is too large for our computers memory.
\item Turning this into a logistic classifier.
\item Adding terms to the linear model.
\item How many terms is too many? -- overfitting \& underfitting
\end{itemize}

\section{Decision Trees -- rule-based classifiers}
\label{sec:org997ce32}

\begin{itemize}
\item What is a class/category?
\item Introduction to iris dataset.
\item How might we classify flowers with if-statements?
\item What if we were to visualise these if-statements.
\item An algorithm for identifying rules.
\item Random forests
\end{itemize}

\section{Instance-based classifiers - k-nearest neighbour and clustering}
\label{sec:org5355ddd}

\begin{itemize}
\item What is a k-nearest neighbour.
\item Distance functions.
\item Finding nearest neighbours effectively.
\item How do the results compare with different k.
\item What is iterative based clustering.
\end{itemize}

\section{Support vector machines}
\label{sec:org9bb7b4a}

\begin{itemize}
\item Maximum margin intuition
\item Solving non-linear problems using Kernel SVM
\item Soft and hard-svm
\item norm-regularisation
\end{itemize}

\section{Bayesian analysis}
\label{sec:org99ed39c}

\begin{itemize}
\item Bayes formula
\item Predicting likelihood with Bayes
\item Bayesian networks
\end{itemize}

\section{Evaluation of Machine Learning methods}
\label{sec:org71d835c}

\begin{itemize}
\item Training, validation, and testing sets
\item Cross-validation (k-fold cross-validation)
\item Precision-recall, ROC curves
\item Confusion matrices
\item Bootstrapping
\end{itemize}
\end{document}
